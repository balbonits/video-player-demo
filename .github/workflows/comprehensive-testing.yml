name: Comprehensive Video Player Testing
# Sam (QA) - Enterprise-level CI/CD pipeline with 90% coverage enforcement

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run performance tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  COVERAGE_THRESHOLD: 90
  PERFORMANCE_BUDGET_FAIL_THRESHOLD: 5

jobs:
  # Quality Gates - Must pass before other jobs
  quality-gates:
    name: Quality Gates & Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          cd apps/web-player-pages && npm ci
          cd ../streaming-backend && npm ci

      - name: Lint frontend code
        run: |
          cd apps/web-player-pages
          npm run lint

      - name: TypeScript check
        run: |
          cd apps/web-player-pages
          npx tsc --noEmit

      - name: Security audit
        run: |
          npm audit --audit-level=high
          cd apps/web-player-pages && npm audit --audit-level=high
          cd ../streaming-backend && npm audit --audit-level=high

  # Unit & Integration Tests with Coverage
  frontend-tests:
    name: Frontend Testing (90% Coverage)
    runs-on: ubuntu-latest
    needs: quality-gates
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          cd apps/web-player-pages
          npm ci

      - name: Run unit tests with coverage
        run: |
          cd apps/web-player-pages
          npm run test:ci
        env:
          CI: true

      - name: Verify coverage thresholds
        run: |
          cd apps/web-player-pages
          node -e "
            const coverage = require('./coverage/coverage-summary.json');
            const total = coverage.total;
            console.log('Coverage Results:');
            console.log('Lines:', total.lines.pct + '%');
            console.log('Functions:', total.functions.pct + '%');
            console.log('Branches:', total.branches.pct + '%');
            console.log('Statements:', total.statements.pct + '%');

            const threshold = ${{ env.COVERAGE_THRESHOLD }};
            if (total.lines.pct < threshold || total.functions.pct < threshold ||
                total.branches.pct < threshold || total.statements.pct < threshold) {
              console.error('Coverage below threshold of ' + threshold + '%');
              process.exit(1);
            }
            console.log('âœ… All coverage thresholds met');
          "

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          directory: ./apps/web-player-pages/coverage/
          flags: frontend
          name: frontend-coverage

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: frontend-test-results
          path: |
            apps/web-player-pages/test-results/
            apps/web-player-pages/coverage/

  # Backend Tests
  backend-tests:
    name: Backend Streaming API Tests
    runs-on: ubuntu-latest
    needs: quality-gates
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          cd apps/streaming-backend
          npm ci

      - name: Start backend for testing
        run: |
          cd apps/streaming-backend
          npm start &
          sleep 10
        env:
          NODE_ENV: test
          PORT: 8080

      - name: Run backend tests with coverage
        run: |
          cd apps/streaming-backend
          npm run test

      - name: Upload backend coverage
        uses: codecov/codecov-action@v3
        with:
          directory: ./apps/streaming-backend/coverage/
          flags: backend
          name: backend-coverage

      - name: Upload backend test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: backend-test-results
          path: apps/streaming-backend/test-results/

  # Cross-Browser E2E Tests
  e2e-tests:
    name: Cross-Browser E2E Tests
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests]
    strategy:
      matrix:
        browser: [chromium, firefox, webkit]
        device: [desktop, mobile, smart-tv]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          cd apps/web-player-pages
          npm ci

      - name: Install Playwright browsers
        run: |
          cd apps/web-player-pages
          npx playwright install --with-deps ${{ matrix.browser }}

      - name: Start application
        run: |
          cd apps/web-player-pages
          npm run build
          npm start &
          cd ../streaming-backend
          npm start &
          sleep 30
        env:
          NODE_ENV: production

      - name: Wait for applications to be ready
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:3000/health; do sleep 2; done'
          timeout 60 bash -c 'until curl -f http://localhost:8080/health; do sleep 2; done'

      - name: Run E2E tests
        run: |
          cd apps/web-player-pages
          npx playwright test --project=${{ matrix.device }}-${{ matrix.browser }}
        env:
          BROWSER: ${{ matrix.browser }}
          DEVICE_TYPE: ${{ matrix.device }}

      - name: Upload E2E test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-results-${{ matrix.browser }}-${{ matrix.device }}
          path: |
            apps/web-player-pages/test-results/
            apps/web-player-pages/playwright-report/

  # Accessibility Testing (WCAG 2.1 AA)
  accessibility-tests:
    name: WCAG 2.1 AA Compliance
    runs-on: ubuntu-latest
    needs: frontend-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          cd apps/web-player-pages
          npm ci

      - name: Install Playwright
        run: |
          cd apps/web-player-pages
          npx playwright install --with-deps chromium

      - name: Start application
        run: |
          cd apps/web-player-pages
          npm run build
          npm start &
          sleep 30

      - name: Run accessibility tests
        run: |
          cd apps/web-player-pages
          npx playwright test --project=accessibility
        env:
          CI: true

      - name: Upload accessibility results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: accessibility-test-results
          path: |
            apps/web-player-pages/test-results/accessibility/
            apps/web-player-pages/accessibility-report/

  # Performance Testing with Lighthouse CI
  performance-tests:
    name: Performance & Core Web Vitals
    runs-on: ubuntu-latest
    needs: frontend-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          cd apps/web-player-pages
          npm ci
          npm install -g @lhci/cli@0.12.x

      - name: Build application
        run: |
          cd apps/web-player-pages
          npm run build

      - name: Start application for testing
        run: |
          cd apps/web-player-pages
          npm start &
          cd ../streaming-backend
          npm start &
          sleep 30

      - name: Run Lighthouse CI
        run: |
          cd apps/web-player-pages
          lhci autorun
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      - name: Run Smart TV performance tests
        run: |
          cd apps/web-player-pages
          npm run lighthouse:tv

      - name: Generate performance report
        run: |
          cd apps/web-player-pages
          npm run performance:analyze

      - name: Upload performance results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: performance-test-results
          path: |
            apps/web-player-pages/.lighthouseci/
            apps/web-player-pages/lighthouse-results/

  # Smart TV Simulation Tests
  smart-tv-tests:
    name: Smart TV Platform Tests
    runs-on: ubuntu-latest
    needs: frontend-tests
    strategy:
      matrix:
        platform: [roku, tizen, vizio, webos]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          cd apps/web-player-pages
          npm ci

      - name: Install Playwright
        run: |
          cd apps/web-player-pages
          npx playwright install --with-deps chromium

      - name: Start application
        run: |
          cd apps/web-player-pages
          npm run build
          npm start &
          sleep 30

      - name: Run Smart TV tests
        run: |
          cd apps/web-player-pages
          npx playwright test tests/e2e/smart-tv-navigation.spec.ts --project=smart-tv
        env:
          SMART_TV_PLATFORM: ${{ matrix.platform }}

      - name: Upload Smart TV test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: smart-tv-results-${{ matrix.platform }}
          path: apps/web-player-pages/test-results/

  # Security Testing
  security-tests:
    name: Security Vulnerability Scan
    runs-on: ubuntu-latest
    needs: quality-gates
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

      - name: OWASP ZAP Baseline Scan
        uses: zaproxy/action-baseline@v0.7.0
        with:
          target: 'http://localhost:3000'

  # Deployment & Release
  deployment:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [e2e-tests, accessibility-tests, performance-tests, security-tests]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install Vercel CLI
        run: npm install -g vercel

      - name: Deploy to Vercel
        run: |
          cd apps/web-player-pages
          vercel --token=${{ secrets.VERCEL_TOKEN }} --prod
        env:
          VERCEL_PROJECT_ID: ${{ secrets.VERCEL_PROJECT_ID }}
          VERCEL_ORG_ID: ${{ secrets.VERCEL_ORG_ID }}

      - name: Post-deployment smoke tests
        run: |
          cd apps/web-player-pages
          # Run minimal smoke tests on production
          npx playwright test tests/e2e/simple-test.spec.ts --project=chrome-desktop

  # Test Results Summary
  test-summary:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [frontend-tests, backend-tests, e2e-tests, accessibility-tests, performance-tests, smart-tv-tests]
    if: always()
    steps:
      - name: Download all test artifacts
        uses: actions/download-artifact@v3

      - name: Generate test summary
        run: |
          echo "# Video Player Demo Test Results" > test-summary.md
          echo "" >> test-summary.md
          echo "## Coverage Summary" >> test-summary.md
          echo "- Frontend Coverage: View artifacts" >> test-summary.md
          echo "- Backend Coverage: View artifacts" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Test Results" >> test-summary.md
          echo "- E2E Tests: ${{ needs.e2e-tests.result }}" >> test-summary.md
          echo "- Accessibility: ${{ needs.accessibility-tests.result }}" >> test-summary.md
          echo "- Performance: ${{ needs.performance-tests.result }}" >> test-summary.md
          echo "- Smart TV: ${{ needs.smart-tv-tests.result }}" >> test-summary.md
          echo "" >> test-summary.md
          echo "Generated on: $(date)" >> test-summary.md

      - name: Comment PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Upload consolidated test results
        uses: actions/upload-artifact@v3
        with:
          name: all-test-results-summary
          path: test-summary.md